{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dd2f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8918c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 124 files from 'belly pain'...\n",
      "Completed processing 'belly pain'\n",
      "Processing 108 files from 'burping'...\n",
      "Completed processing 'burping'\n",
      "Processing 108 files from 'cold_hot'...\n",
      "Completed processing 'cold_hot'\n",
      "Processing 135 files from 'discomfort'...\n",
      "Completed processing 'discomfort'\n",
      "Processing 382 files from 'hungry'...\n",
      "Completed processing 'hungry'\n",
      "Processing 108 files from 'laugh'...\n",
      "Completed processing 'laugh'\n",
      "Processing 108 files from 'noise'...\n",
      "Completed processing 'noise'\n",
      "Processing 108 files from 'silence'...\n",
      "Completed processing 'silence'\n",
      "Processing 132 files from 'tired'...\n",
      "Completed processing 'tired'\n",
      "\n",
      "All categories processed - original spectrograms created!\n"
     ]
    }
   ],
   "source": [
    "input_base_dir = 'BCS'\n",
    "\n",
    "categories = ['belly pain', 'burping', 'cold_hot', 'discomfort', 'hungry', 'laugh', 'noise', 'silence', 'tired']\n",
    "\n",
    "output_base_dir = 'BCS/spectrograms'\n",
    "\n",
    "for category in categories:\n",
    "    input_path = os.path.join(input_base_dir, category)\n",
    "    output_path = os.path.join(output_base_dir, category)\n",
    "    \n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"Warning: Input directory '{input_path}' does not exist\")\n",
    "        continue\n",
    "    \n",
    "    audio_files = [f for f in os.listdir(input_path) if f.endswith(('.wav', '.mp3', '.flac', '.ogg'))]\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(f\"No audio files found in '{input_path}'\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Processing {len(audio_files)} files from '{category}'...\")\n",
    "    \n",
    "    for file in audio_files:\n",
    "        filepath = os.path.join(input_path, file)\n",
    "        \n",
    "        try:\n",
    "            y, sr = librosa.load(filepath, sr=22050)\n",
    "            \n",
    "            S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
    "            S_db = librosa.power_to_db(S, ref=np.max)\n",
    "            \n",
    "            plt.figure(figsize=(10, 4))\n",
    "            librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='mel')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            output_filename = os.path.splitext(file)[0] + '.png'\n",
    "            save_path = os.path.join(output_path, output_filename)\n",
    "            plt.savefig(save_path, bbox_inches='tight', pad_inches=0)\n",
    "            plt.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {str(e)}\")\n",
    "    \n",
    "    print(f\"Completed processing '{category}'\")\n",
    "\n",
    "print(\"\\nAll categories processed - original spectrograms created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "433e8271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 124 files from 'belly pain'...\n",
      "Completed processing 'belly pain'\n",
      "Processing 108 files from 'burping'...\n",
      "Completed processing 'burping'\n",
      "Processing 108 files from 'cold_hot'...\n",
      "Completed processing 'cold_hot'\n",
      "Processing 135 files from 'discomfort'...\n",
      "Completed processing 'discomfort'\n",
      "Processing 382 files from 'hungry'...\n",
      "Completed processing 'hungry'\n",
      "Processing 108 files from 'laugh'...\n",
      "Completed processing 'laugh'\n",
      "Processing 108 files from 'noise'...\n",
      "Completed processing 'noise'\n",
      "Processing 108 files from 'silence'...\n",
      "Completed processing 'silence'\n",
      "Processing 132 files from 'tired'...\n",
      "Completed processing 'tired'\n",
      "\n",
      "All categories processed with frequency filtering!\n"
     ]
    }
   ],
   "source": [
    "input_base_dir = 'BCS'\n",
    "\n",
    "categories = ['belly pain', 'burping', 'cold_hot', 'discomfort', 'hungry', 'laugh', 'noise', 'silence', 'tired']\n",
    "\n",
    "output_base_dir = 'BCS/spectrograms_filtered'\n",
    "\n",
    "for category in categories:\n",
    "    input_path = os.path.join(input_base_dir, category)\n",
    "    output_path = os.path.join(output_base_dir, category)\n",
    "    \n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"Warning: Input directory '{input_path}' does not exist\")\n",
    "        continue\n",
    "    \n",
    "    audio_files = [f for f in os.listdir(input_path) if f.endswith(('.wav', '.mp3', '.flac', '.ogg'))]\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(f\"No audio files found in '{input_path}'\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Processing {len(audio_files)} files from '{category}'...\")\n",
    "    \n",
    "    for file in audio_files:\n",
    "        filepath = os.path.join(input_path, file)\n",
    "        \n",
    "        try:\n",
    "            y, sr = librosa.load(filepath, sr=22050)\n",
    "            \n",
    "            S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
    "            S_db = librosa.power_to_db(S, ref=np.max)\n",
    "            \n",
    "            threshold = np.mean(S_db) + np.std(S_db)\n",
    "            mask = S_db > threshold\n",
    "            \n",
    "            freq_indices = np.where(np.sum(mask, axis=1) > 0)[0]\n",
    "            time_indices = np.where(np.sum(mask, axis=0) > 0)[0]\n",
    "            \n",
    "            if len(freq_indices) == 0 or len(time_indices) == 0:\n",
    "                print(f\"  Skipping {file} - no significant content\")\n",
    "                continue\n",
    "            \n",
    "            S_filtered = S_db[freq_indices, :]\n",
    "            S_filtered = S_filtered[:, time_indices]\n",
    "            \n",
    "            plt.figure(figsize=(10, 4))\n",
    "            librosa.display.specshow(S_filtered, sr=sr, x_axis='time', y_axis='mel')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            output_filename = os.path.splitext(file)[0] + '.png'\n",
    "            save_path = os.path.join(output_path, output_filename)\n",
    "            plt.savefig(save_path, bbox_inches='tight', pad_inches=0)\n",
    "            plt.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {str(e)}\")\n",
    "    \n",
    "    print(f\"Completed processing '{category}'\")\n",
    "\n",
    "print(\"\\nAll categories processed with frequency filtering!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "174199f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spectrogram images...\n",
      "Loading 124 images from 'belly pain'...\n",
      "Loading 108 images from 'burping'...\n",
      "Loading 108 images from 'cold_hot'...\n",
      "Loading 135 images from 'discomfort'...\n",
      "Loading 382 images from 'hungry'...\n",
      "Loading 108 images from 'laugh'...\n",
      "Loading 108 images from 'noise'...\n",
      "Loading 108 images from 'silence'...\n",
      "Loading 132 images from 'tired'...\n",
      "\n",
      "Balancing dataset...\n",
      "\n",
      "Dataset balanced!\n",
      "Total samples: 972\n",
      "Samples per class: 108\n",
      "\n",
      "Class distribution:\n",
      "  belly pain: 108 samples\n",
      "  burping: 108 samples\n",
      "  cold_hot: 108 samples\n",
      "  discomfort: 108 samples\n",
      "  hungry: 108 samples\n",
      "  laugh: 108 samples\n",
      "  noise: 108 samples\n",
      "  silence: 108 samples\n",
      "  tired: 108 samples\n",
      "\n",
      "Normalizing pixel values...\n",
      "\n",
      "Splitting into train and test sets...\n",
      "\n",
      "Dataset Summary:\n",
      "Training samples: 777\n",
      "Test samples: 195\n",
      "\n",
      "Training class distribution:\n",
      "  belly pain: 86 samples\n",
      "  burping: 87 samples\n",
      "  cold_hot: 86 samples\n",
      "  discomfort: 86 samples\n",
      "  hungry: 86 samples\n",
      "  laugh: 87 samples\n",
      "  noise: 86 samples\n",
      "  silence: 87 samples\n",
      "  tired: 86 samples\n",
      "\n",
      "Test class distribution:\n",
      "  belly pain: 22 samples\n",
      "  burping: 21 samples\n",
      "  cold_hot: 22 samples\n",
      "  discomfort: 22 samples\n",
      "  hungry: 22 samples\n",
      "  laugh: 21 samples\n",
      "  noise: 22 samples\n",
      "  silence: 21 samples\n",
      "  tired: 22 samples\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "spectrograms_dir = 'BCS/spectrograms'\n",
    "categories = ['belly pain', 'burping', 'cold_hot', 'discomfort', 'hungry', 'laugh', 'noise', 'silence', 'tired']\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "print(\"Loading spectrogram images...\")\n",
    "\n",
    "for idx, category in enumerate(categories):\n",
    "    category_path = os.path.join(spectrograms_dir, category)\n",
    "    \n",
    "    if not os.path.exists(category_path):\n",
    "        print(f\"Warning: Directory '{category_path}' does not exist\")\n",
    "        continue\n",
    "    \n",
    "    image_files = [f for f in os.listdir(category_path) if f.endswith('.png')]\n",
    "    print(f\"Loading {len(image_files)} images from '{category}'...\")\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(category_path, image_file)\n",
    "        \n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            if img is not None:\n",
    "                img_resized = cv2.resize(img, (224, 224))\n",
    "                X.append(img_resized)\n",
    "                y.append(idx)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {image_file}: {str(e)}\")\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"\\nBalancing dataset...\")\n",
    "class_counts = {}\n",
    "for idx in range(len(categories)):\n",
    "    class_counts[idx] = np.sum(y == idx)\n",
    "\n",
    "min_samples = min(class_counts.values())\n",
    "\n",
    "X_balanced = []\n",
    "y_balanced = []\n",
    "\n",
    "for idx in range(len(categories)):\n",
    "    class_mask = y == idx\n",
    "    class_indices = np.where(class_mask)[0]\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    selected_indices = np.random.choice(class_indices, min_samples, replace=False)\n",
    "    \n",
    "    for i in selected_indices:\n",
    "        X_balanced.append(X[i])\n",
    "        y_balanced.append(y[i])\n",
    "\n",
    "X = np.array(X_balanced)\n",
    "y = np.array(y_balanced)\n",
    "\n",
    "print(f\"\\nDataset balanced!\")\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"Samples per class: {min_samples}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "for idx, category in enumerate(categories):\n",
    "    count = np.sum(y == idx)\n",
    "    print(f\"  {category}: {count} samples\")\n",
    "\n",
    "print(f\"\\nNormalizing pixel values...\")\n",
    "X = X.astype('float32') / 255.0\n",
    "\n",
    "print(f\"\\nSplitting into train and test sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\nDataset Summary:\")\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"\\nTraining class distribution:\")\n",
    "for idx, category in enumerate(categories):\n",
    "    count = np.sum(y_train == idx)\n",
    "    print(f\"  {category}: {count} samples\")\n",
    "print(f\"\\nTest class distribution:\")\n",
    "for idx, category in enumerate(categories):\n",
    "    count = np.sum(y_test == idx)\n",
    "    print(f\"  {category}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efce83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building CNN Model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 222, 222, 32)     128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 111, 111, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 111, 111, 32)      0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 109, 109, 64)     256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 54, 54, 64)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 52, 52, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 26, 26, 128)       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 24, 24, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 24, 24, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 12, 12, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 12, 12, 256)       0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 36864)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               9437440   \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 9)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,863,369\n",
      "Trainable params: 9,861,641\n",
      "Non-trainable params: 1,728\n",
      "_________________________________________________________________\n",
      "\n",
      "Training CNN model...\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 102s 4s/step - loss: 2.8391 - accuracy: 0.2201 - val_loss: 3.5592 - val_accuracy: 0.1077 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 97s 4s/step - loss: 2.2152 - accuracy: 0.3192 - val_loss: 6.1447 - val_accuracy: 0.1077 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 65s 3s/step - loss: 2.0436 - accuracy: 0.3398 - val_loss: 8.4624 - val_accuracy: 0.1077 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 64s 3s/step - loss: 1.8910 - accuracy: 0.3861 - val_loss: 9.6418 - val_accuracy: 0.1077 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 66s 3s/step - loss: 1.8352 - accuracy: 0.3629 - val_loss: 9.9070 - val_accuracy: 0.1077 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - ETA: 0s - loss: 1.7061 - accuracy: 0.4106\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "25/25 [==============================] - 66s 3s/step - loss: 1.7061 - accuracy: 0.4106 - val_loss: 11.0888 - val_accuracy: 0.1077 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "23/25 [==========================>...] - ETA: 5s - loss: 1.7128 - accuracy: 0.4090"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Building CNN Model...\")\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "    \n",
    "    layers.Dense(len(categories), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "print(\"\\nTraining CNN model...\")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nModel training completed!\")\n",
    "\n",
    "print(\"\\nEvaluating model on training set...\")\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(f\"Train Accuracy: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nEvaluating model on test set...\")\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "\n",
    "print(f\"Overfitting Gap: {(train_accuracy - test_accuracy)*100:.2f}%\")\n",
    "\n",
    "y_pred_probs = model.predict(X_test, verbose=0)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=categories))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=categories, yticklabels=categories)\n",
    "plt.title(f'Confusion Matrix - CNN Model\\nTrain Accuracy: {train_accuracy:.2%} | Test Accuracy: {test_accuracy:.2%} | Gap: {(train_accuracy - test_accuracy)*100:.1f}%')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPer-class Accuracy:\")\n",
    "for idx, category in enumerate(categories):\n",
    "    class_mask = y_test == idx\n",
    "    if np.sum(class_mask) > 0:\n",
    "        class_accuracy = accuracy_score(y_test[class_mask], y_pred[class_mask])\n",
    "        print(f\"  {category}: {class_accuracy:.4f} ({class_accuracy*100:.2f}%)\")\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Test Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Test Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
